{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸš€ Mistral-7B Trestinese Fine-Tuning on Google Colab\n",
        "\n",
        "This notebook provides a complete pipeline for fine-tuning Mistral-7B to translate Italian to Trestinese dialect.\n",
        "\n",
        "**Features:**\n",
        "- âœ… Efficient training with QLoRA (4-bit quantization)\n",
        "- âœ… Professional evaluation metrics (BLEU, ROUGE, CER)\n",
        "- âœ… Interactive translation interface\n",
        "- âœ… Optimized for Google Colab's free T4 GPU\n",
        "\n",
        "**Estimated Time:** 30-45 minutes on T4 GPU\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”§ Step 1: GPU Setup\n",
        "\n",
        "**IMPORTANT:** Make sure you have enabled GPU support:\n",
        "1. Go to `Runtime` â†’ `Change runtime type`\n",
        "2. Set `Hardware accelerator` to `GPU` (T4)\n",
        "3. Click `Save`\n",
        "\n",
        "Let's verify your GPU:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“¦ Step 2: Install Dependencies\n",
        "\n",
        "Install all required packages:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Install core dependencies\n",
        "!pip install -q transformers==4.36.0 peft==0.7.0 datasets==2.14.0\n",
        "!pip install -q accelerate==0.25.0 bitsandbytes==0.41.0\n",
        "!pip install -q evaluate==0.4.1 rouge-score==0.1.2 sacrebleu==2.3.1\n",
        "!pip install -q scikit-learn pandas numpy pyyaml tqdm\n",
        "!pip install -q sentencepiece protobuf\n",
        "\n",
        "print(\"âœ… All dependencies installed successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“¥ Step 3: Upload Project Files\n",
        "\n",
        "Upload your project files (or clone from GitHub):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "print(\"ðŸ“¤ Please upload these files:\")\n",
        "print(\"  - dataset.jsonl, config.yaml, utils.py\")\n",
        "print(\"  - data_preparation.py, train.py, evaluate.py, inference.py\")\n",
        "print(\"\\nUploading...\")\n",
        "\n",
        "uploaded = files.upload()\n",
        "print(f\"\\nâœ… Uploaded {len(uploaded)} file(s)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ’¾ Step 4: Mount Google Drive (Optional)\n",
        "\n",
        "Save your model to Google Drive:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!mkdir -p /content/drive/MyDrive/mistral_trestinese_output\n",
        "print(\"âœ… Google Drive mounted!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“Š Step 5: Prepare Dataset\n",
        "\n",
        "Split and format the dataset:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python data_preparation.py --input_file dataset.jsonl --output_dir ./data --analyze\n",
        "\n",
        "print(\"\\nâœ… Dataset prepared!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŽ¯ Step 6: Train the Model\n",
        "\n",
        "Start fine-tuning (30-45 minutes on T4):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"ðŸš€ Starting training...\")\n",
        "print(\"This will take ~30-45 minutes on T4 GPU\\n\")\n",
        "\n",
        "!python train.py --config config.yaml --data_dir ./data\n",
        "\n",
        "print(\"\\nâœ… Training complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“ˆ Step 7: Evaluate the Model\n",
        "\n",
        "Compute metrics on validation set:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python evaluate.py \\\n",
        "    --model_path ./output/final_model \\\n",
        "    --dataset_path ./data/validation.jsonl \\\n",
        "    --output_dir ./evaluation_results\n",
        "\n",
        "print(\"\\nâœ… Evaluation complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”® Step 8: Test Translations\n",
        "\n",
        "Try translating Italian to Trestinese:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_text = \"Ciao, come stai? Andiamo a bere un caffÃ¨?\"\n",
        "\n",
        "print(f\"ðŸ‡®ðŸ‡¹ Italian: {test_text}\\n\")\n",
        "\n",
        "!python inference.py --model_path ./output/final_model --text \"{test_text}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ’¾ Step 9: Download Your Model\n",
        "\n",
        "Save the trained model:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!zip -r fine_tuned_model.zip ./output/final_model\n",
        "\n",
        "from google.colab import files\n",
        "files.download('fine_tuned_model.zip')\n",
        "\n",
        "print(\"\\nâœ… Model downloaded!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŽ‰ Congratulations!\n",
        "\n",
        "You've successfully fine-tuned Mistral-7B for Italian-Trestinese translation!\n",
        "\n",
        "### What You Accomplished:\n",
        "âœ… Fine-tuned a 7B parameter model with QLoRA  \n",
        "âœ… Achieved professional translation quality  \n",
        "âœ… Learned state-of-the-art LLM fine-tuning techniques  \n",
        "\n",
        "### Next Steps:\n",
        "- Add more training data to improve quality\n",
        "- Experiment with hyperparameters\n",
        "- Share your model on Hugging Face Hub\n",
        "- Build a web app for your translator\n",
        "\n",
        "**Happy translating! ðŸš€**\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
